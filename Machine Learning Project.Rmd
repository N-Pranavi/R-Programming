---
title: "Machine Learning Project"
---


```{r warning = FALSE, message = FALSE}
# Suppress dplyr summarise grouping warning messages
options(dplyr.summarise.inform = FALSE)

library(tidyverse)
library(tidymodels)
library(kknn)
library(klaR)

credit_card_df <- readRDS(url('https://gmubusinessanalytics.netlify.app/data/credit_card_df.rds'))

credit_card_df
```



# Data Analysis

In this section, you must think of at least 5 relevant questions that explore the relationship between `customer_status` and the other variables in the `credit_card_df` data set. The goal of your analysis should be discovering which variables drive the differences between customers who do and do not close their account.

You must answer each question and provide supporting data summaries with either a summary data frame (using `dplyr`/`tidyr`) or a plot (using `ggplot`) or both.

In total, you must have a minimum of 3 plots (created with `ggplot`) and 3 summary data frames (created with `dplyr`) for the exploratory data analysis section. Among the plots you produce, you must have at least 3 different types (ex. box plot, bar chart, histogram, scatter plot, etc...)

See the [Data Analysis Project](https://gmubusinessanalytics.netlify.app/data-analysis-project.html){target="_blank"} for an example of a question answered with a summary table and plot.

**Note**: To add an R code chunk to any section of your project, you can use the keyboard shortcut `Ctrl` + `Alt` + `i` or the `insert` button at the top of your R project template notebook file.



# Question 1


**Question**:Does employee status has affect based on the income and age?


**Answer**: According to the graph below, age has a significant impact in the number of closed accounts; the age group 45-64 has the highest number of closed accounts when compared to the age group 18-44. The percentage of closed accounts in the 18-44 age group is lower, indicating that customers in this age group will stay active for longer periods of time.


```{r}
data_by_age <- credit_card_df %>% mutate(agegroup = case_when(age >= 18  & age <= 44 ~ '18-44',
                                             age >= 45  & age <= 64 ~ '45-64',
                                             age >= 65 ~ '65+'))

customer_count <- table(data_by_age$customer_status, data_by_age$agegroup)
barplot(customer_count, main="Age distribution by customer status",
  xlab="Age", ylab = "Customer count",col=c("orange","skyblue"),
  legend = rownames(counts), beside=TRUE)



```



# Question 2


**Question**: How is Customer status related to income and employment status?


**Answer**: From  below scatter plot, When we compare the income and employment status of full-time employees to their customer status in our data collection, we can observe that their customer status is active. In comparison, the status of the self-employed as a customer is closed. When comparing full-time employees to self-employed people, we may assume that full-time employees are able to keep their customer status active.


```{r}

ggplot(data=credit_card_df,mapping=aes(x=income,y=employment_status))+
  geom_jitter(color='#FF7F50',alpha=0.50)+
   facet_grid(~ customer_status)+
  labs(title = "Customer status based on income and employment status",
       x="Income",
       y="Employment status")

```


# Question 3


**Question**:How is Customer status related to employment status and credit limit?


**Answer**: From  below area plot, When comparing job status and credit limit to customer status, consumers who are employed full-time and have an active customer status have a higher credit limit. When consumers' employment status is self-employed, their credit limit is reduced, and their customer status is closed account.


```{r}
ggplot(data=credit_card_df,mapping=aes(x=customer_status,y=credit_limit))+
  geom_area(color='#FF0000',alpha=0.50)+
   facet_grid(~ employment_status)+
  labs(title = "Employement status Vs credit limit",
       x="Customer status",
       y="Credit limit")


```



# Question 4


**Question**: How is customer status related to months inactive last year?


**Answer**: From below summary, The total number of customers with a closed account is 2092, with an average of 2.69 months inactive and a maximum of 6. Similarly, the total number of active customers is 2535, with an average of 2.26 months inactive previous year and a maximum of 6. Customers who had been idle for a long time had their accounts closed as a result of this.


```{r}

credit_card_df %>% group_by(customer_status) %>%
    summarise(n_customers = n(),
           min_months_inactive_last_year= min(months_inactive_last_year),
           avg_months_inactive_last_year = mean(months_inactive_last_year),
           max_months_inactive_last_year= max(months_inactive_last_year))


```



# Question 5


**Question**: How is  utilization ratio related to customer status ?


**Answer**: From below summary, the total number of customers that have closed their accounts is 2092, with an average utilization ratio of 0.161 and a maximum of 0.999. Similarly, there are 2535 customers with an active customer status, with an average utilization ratio of 0.289 and a maximum usage ratio of 0.983. In comparison to active customers, customers with the highest use ratio have closed their accounts.


```{r}

credit_card_df %>% group_by(customer_status) %>%  
  summarise(customer_count = n(), 
            min_utilization_ratio= min(utilization_ratio), 
            avg_utilization_ratio = mean(utilization_ratio),  
            max_utilization_ratio= max(utilization_ratio))

```




# Machine Learning


In this section of the project, you will fit **three classification algorithms** to predict the outcome variable,`customer_status`.

You must follow the machine learning steps below. 

The data splitting and feature engineering steps should only be done once so that your models are using the same data and feature engineering steps for training.

- Split the `credit_card_df` data into a training and test set (remember to set your seed)
- Specify a feature engineering pipeline with the `recipes` package
    - You can include steps such as skewness transformation, correlation filters, dummy variable encoding or any other steps you find appropriate
- Specify a `parsnip` model object
    - You may choose from the following classification algorithms:
      - Logistic Regression
      - LDA
      - QDA
      - KNN
      - Decision Tree
      - Random Forest
- Package your recipe and model into a workflow
- Fit your workflow to the training data
    - If your model has hyperparameters:
      - Split the training data into 5 folds for 5-fold cross validation using `vfold_cv` (remember to set your seed)
      - Perform hyperparamter tuning with a random grid search using the `grid_random()` function
      - Refer to the following tutorial for an example - [Random Grid Search](https://gmubusinessanalytics.netlify.app/lesson-08-r-tutorial.html#Hyperparameter_Tuning14){target="_blank"}
      - Hyperparameter tuning can take a significant amount of computing time. Be careful not to set the `size` argument of `grid_random()` too large. I recommend `size` = 10 or smaller.
      - Select the best model with `select_best()` and finalize your workflow
- Evaluate model performance on the test set by plotting an ROC curve using `autoplot()` and calculating the area under the ROC curve on your test data

```{r}
set.seed(271)

credit_split <- initial_split( credit_card_df , prop = 0.75,
                              strata = customer_status)

credit_training <- credit_split %>% training()

credit_test <- credit_split%>% testing()


#Feature Engineering 

credit_recipe <- recipe(customer_status ~., data = credit_card_df) %>% 
                 step_YeoJohnson(all_numeric(), -all_outcomes()) %>% 
                 step_normalize(all_numeric(), -all_outcomes()) %>% 
                 step_dummy(all_nominal(), -all_outcomes())


credit_recipe %>% 
  prep() %>% 
  bake(new_data = credit_training)


set.seed(271)
credit_folds <- vfold_cv(credit_card_df, v = 5)
levels(credit_card_df$customer_status)
```



# Model 1: Logistic Regression

```{r}

set.seed(271)
logistic_model <- logistic_reg() %>% 
                  set_engine('glm') %>% 
                  set_mode('classification')

logistic_wf <- workflow() %>% 
               add_model(logistic_model) %>% 
               add_recipe(credit_recipe)

logistic_fit <-  logistic_wf %>% 
                 last_fit(split=credit_split)

rlogistic_results <-  logistic_fit %>% 
                      collect_predictions()


roc_curve( rlogistic_results , truth = customer_status , estimate = .pred_closed_account ) %>% 
autoplot()


roc_auc(rlogistic_results, truth = customer_status, .pred_closed_account)


conf_mat(rlogistic_results, truth = customer_status, estimate = .pred_class)

my_metrics<- metric_set(accuracy,f_meas)
my_metrics(rlogistic_results,truth=customer_status,estimate=.pred_class)


```





# Model 2: KNN

```{r}


set.seed(314)
knn_model <- nearest_neighbor(neighbors =tune()) %>% 
             set_engine('kknn') %>% 
             set_mode('classification')


knn_wf <- workflow() %>% 
          add_model(knn_model) %>% 
          add_recipe(credit_recipe)


k_grid <- tibble(neighbors = c(10, 15, 25, 45, 60, 80, 100, 120, 140, 180))



set.seed(314)

knn_tuning <- knn_wf %>% 
              tune_grid(resamples = credit_folds, grid = k_grid)

best_k <- knn_tuning %>% 
          select_best(metric = 'roc_auc')

final_knn_wf <- knn_wf %>% 
                finalize_workflow(best_k)

knn_fit <- final_knn_wf %>% 
           last_fit(split = credit_split)

knn_results <-   knn_fit %>% 
                 collect_predictions()

roc_curve( knn_results , truth = customer_status , estimate = .pred_closed_account ) %>% 
  autoplot()


roc_auc(knn_results, truth = customer_status, .pred_closed_account)


conf_mat(knn_results, truth = customer_status, estimate = .pred_class)

my_metrics<- metric_set(accuracy,f_meas)
my_metrics(knn_results,truth=customer_status,estimate=.pred_class)




```





# Model 3: LDA

```{r}

library(lda)
library(discrim)
lda_model <- discrim_regularized(frac_common_cov = 1) %>%
             set_engine('klaR') %>%
             set_mode('classification')


lda_wf <- workflow() %>%
          add_model(lda_model) %>%
          add_recipe(credit_recipe)

## Fit Model

lda_fit <-  lda_wf %>%
                 last_fit(split=credit_split)

## Collect Predictions

lda_results <-   lda_fit %>%
                 collect_predictions()

## ROC Curve
roc_curve(lda_results, truth = customer_status , estimate = .pred_closed_account ) %>%
  autoplot()

# ROC AUC
roc_auc(lda_results, truth = customer_status , .pred_closed_account)


# Confusion Matrix
conf_mat(lda_results, truth =customer_status, estimate = .pred_class)
my_metrics<- metric_set(accuracy,f_meas)
my_metrics(lda_results,truth=customer_status,estimate=.pred_class)


```




# Summary of Results

Write a summary of your overall findings and recommendations to the executives at the bank. Think of this section as your closing remarks of a presentation, where you summarize your key findings, model performance, and make recommendations to improve customer retention and service at the bank.

Your executive summary must be written in a [professional tone](https://www.universalclass.com/articles/writing/business-writing/appropriate-tone-in-business-communications.htm){target="_blank"}, with minimal grammatical errors, and should include the following sections:

1. An introduction where you explain the business problem and goals of your data analysis

    - What problem(s) is this company trying to solve? Why are they important to their future success?
  
    - What was the goal of your analysis? What questions were you trying to answer and why do they matter?

<br>

2. Highlights and key findings from your Exploratory Data Analysis section 
    - What were the interesting findings from your analysis and **why are they important for the business**?

    - This section is meant to **establish the need for your recommendations** in the following section

<br>

3. Your “best” classification model and an analysis of its performance 
    - In this section you should talk about the expected error of your model on future data
      - To estimate future performance, you can use your model performance results on the **test data**
    - You should discuss at least one performance metric, such as an F1, sensitivity, specificity, or ROC AUC for your model. However, you must explain the results in an **intuitive, non-technical manner**. Your audience in this case are executives at a bank with limited knowledge of machine learning.

<br>

4. Your recommendations to the bank on how to reduce the number of customers closing their credit card accounts 
  
    - Each recommendation must be supported by your data analysis results 

    - You must clearly explain why you are making each recommendation and which results from your data analysis support this recommendation

    - You must also describe the potential business impact of your recommendation:
      
      - Why is this a good recommendation? 
      
      - What benefits will the business achieve?


**Summary**

Add your summary here. Please do not place your text within R code chunks.

->The company is focusing on finding what elements are influencing account closures and how to enhance client drive to the bank. As the bank reduces the number of accounts it closes, it will automatically increase its earnings.

My goal of my data analysis is to determine which variables are responsible for the differences between customers who close their accounts and those who do not. Using the data and comparing all of the variables in the data set to the customer status to determine what reasons are driving the difference.

-> The highlights and key points from data analysis are:

Age has a significant impact in the number of closed accounts.
The customer status is active for full-time time employees for their income.
consumers who are employed full-time and have an active customer status have a higher credit limit.


->From the machine learning models, the Logistic Regression model has a better accuracy and prediction compared to knn model and linear discriminant analysis.

LOGISTIC REGRESSION:

The roc_auc curve has accuracy of 93% which is extremely good. From this we can see good performance of the logistic regression model.

-> Some of the recommendations are:
Age has a significant impact in the number of closed accounts; the age group 45-64 has the highest number of closed accounts when compared to the age group 18-44. The percentage of closed accounts in the 18-44 age group is lower, indicating that customers in this age group will stay active for longer periods of time.

When we compare the income and employment status of full-time employees to their customer status in our data collection, we can observe that their customer status is active. In comparison, the status of the self-employed as a customer is closed. When comparing full-time employees to self-employed people, we may assume that full-time employees are able to keep their customer status active.

When comparing job status and credit limit to customer status, consumers who are employed full-time and have an active customer status have a higher credit limit. When consumers' employment status is self-employed, their credit limit is reduced, and their customer status is closed account.

The total number of customers with a closed account is 2092, with an average of 2.69 months inactive and a maximum of 6. Similarly, the total number of active customers is 2535, with an average of 2.26 months inactive previous year and a maximum of 6. Customers who had been idle for a long time had their accounts closed as a result of this.

The total number of customers that have closed their accounts is 2092, with an average utilization ratio of 0.161 and a maximum of 0.999. Similarly, there are 2535 customers with an active customer status, with an average utilization ratio of 0.289 and a maximum usage ratio of 0.983. In comparison to active customers, customers with the highest use ratio have closed their accounts.
